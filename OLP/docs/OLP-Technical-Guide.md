# OLP (Otimizador de Localidade Preditivo) - Guia T√©cnico Completo

## üìã √çndice
1. [Vis√£o Geral](#vis√£o-geral)
2. [Arquitetura do Sistema](#arquitetura-do-sistema)
3. [Componentes Principais](#componentes-principais)
4. [Fluxo de Execu√ß√£o](#fluxo-de-execu√ß√£o)
5. [Decis√£o OLP-ALP](#decis√£o-olp-alp)
6. [Integra√ß√£o e Uso](#integra√ß√£o-e-uso)
7. [Exemplos Pr√°ticos](#exemplos-pr√°ticos)
8. [Pr√≥ximos Passos](#pr√≥ximos-passos)

---

## Vis√£o Geral

O **OLP (Otimizador de Localidade Preditivo)** √© um sistema h√≠brido de hardware-software que otimiza a execu√ß√£o de tarefas sens√≠veis √† lat√™ncia (IA, Big Data, HPC) decidindo dinamicamente se devem ser executadas em:

- **PIM (Processing-in-Memory)**: Hardware especializado, ultra-r√°pido, com lat√™ncia baixa
- **CPU**: Processador geral, com maior flexibilidade

### Objetivos Principais

| Objetivo | Descri√ß√£o | M√©trica |
|----------|-----------|---------|
| **Rigor** | Decis√µes baseadas em confian√ßa >= 99.9% | Confian√ßa do ML |
| **Ganho** | Otimiza√ß√£o de lat√™ncia (TTID) | TTID_CPU - TTID_PIM |
| **Seguran√ßa** | Recovery autom√°tico em caso de falhas cr√≠ticas | Taxa de sucesso 100% |
| **Lat√™ncia** | Interface de baixa lat√™ncia para aplica√ß√µes | <1ms overhead |

---

## Arquitetura do Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    APLICA√á√ÉO DO DESENVOLVEDOR                   ‚îÇ
‚îÇ        (Machine Learning, Big Data, High-Performance)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ         OLP Core API (Interface)             ‚îÇ
        ‚îÇ   ‚úì set_context()                           ‚îÇ
        ‚îÇ   ‚úì execute_optimized()                     ‚îÇ
        ‚îÇ   ‚úì register_checkpoint()                   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº                              ‚ñº              ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Tracer ‚îÇ                    ‚îÇML_Model  ‚îÇ   ‚îÇ Recovery   ‚îÇ
    ‚îÇ(M1)    ‚îÇ                    ‚îÇALP(M2)   ‚îÇ   ‚îÇModule(M3)  ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ‚Ä¢ Collect‚îÇ                    ‚îÇ‚Ä¢ Predict ‚îÇ   ‚îÇ‚Ä¢ Checkpoint‚îÇ
    ‚îÇ accesses‚îÇ                    ‚îÇ blocks   ‚îÇ   ‚îÇ‚Ä¢ Rollback  ‚îÇ
    ‚îÇ‚Ä¢ Stride ‚îÇ                    ‚îÇ‚Ä¢ Confidence   ‚îÇ‚Ä¢ Recovery  ‚îÇ
    ‚îÇ pattern ‚îÇ                    ‚îÇ‚Ä¢ TTID est.    ‚îÇ via REM    ‚îÇ
    ‚îÇ‚Ä¢ Context‚îÇ                    ‚îÇ              ‚îÇ            ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                                ‚îÇ            ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  PredictionEngine (Motor de Decis√£o) ‚îÇ
        ‚îÇ      L√≥gica OLP-ALP                  ‚îÇ
        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
        ‚îÇ IF confian√ßa >= 99.9% AND ganho > 0:‚îÇ
        ‚îÇ    ‚Üí Desvia para PIM                 ‚îÇ
        ‚îÇ ELSE:                                ‚îÇ
        ‚îÇ    ‚Üí Executa na CPU                  ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   OLP-HAL Driver (Camada HW)         ‚îÇ
        ‚îÇ   Hardware Abstraction Layer         ‚îÇ
        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
        ‚îÇ ‚Ä¢ load_task_pim() [DMA]              ‚îÇ
        ‚îÇ ‚Ä¢ send_rem_interrupt() [REM]         ‚îÇ
        ‚îÇ ‚Ä¢ Monitor (TTID, Power)              ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚ñº               ‚ñº    ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ PIM Unit ‚îÇ    ‚îÇREM(Opt)‚îÇ  ‚îÇ HW Monitor ‚îÇ
            ‚îÇ(Hardware)‚îÇ    ‚îÇSignal  ‚îÇ  ‚îÇ(TTID, W)   ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Componentes Principais

### 1. **OLPCoreAPI** - Interface Principal

**Arquivo**: `olp_core_api.py`

Interface que o desenvolvedor interage diretamente. Coordena todos os m√≥dulos internos.

#### M√©todos Essenciais:

```python
# 1. Definir Contexto (Obrigat√≥rio)
OLP_API.set_context(
    function_name: str,      # Ex: "training_loop_forward_pass"
    scope_id: int,           # Ex: n√∫mero da itera√ß√£o (1, 2, 3...)
    metadata: Dict = None    # Informa√ß√µes adicionais opcionais
) -> bool

# 2. Executar Tarefa Otimizada (Principal)
result = OLP_API.execute_optimized(
    task_function: Callable,  # Fun√ß√£o a ser executada
    task_data: List,          # Dados / endere√ßos de mem√≥ria
    task_id: int = None       # ID opcional da tarefa
) -> Any

# 3. Registrar Checkpoint (Seguran√ßa)
OLP_API.register_checkpoint(
    recovery_address: int,     # Endere√ßo de estado v√°lido
    checkpoint_name: str = ""  # Nome descritivo
) -> bool

# 4. Ativar Recovery (Emerg√™ncia)
OLP_API.trigger_recovery(
    error_code: int,           # C√≥digo de erro
    context_info: str = ""     # Contexto da falha
) -> bool

# 5. Obter Relat√≥rio Completo
report = OLP_API.get_full_system_report() -> Dict
```

#### Responsabilidades:
- Coordenar Tracer, ML_Model, PredictionEngine, Recovery
- Manter stack de contextos
- Rastrear hist√≥rico de execu√ß√µes
- Fornecer estat√≠sticas e relat√≥rios

---

### 2. **RuntimeTracer (M1)** - Coleta de Dados

**Arquivo**: `runtime_tracer.py`

Coleta padr√µes de acesso √† mem√≥ria em tempo de execu√ß√£o.

#### Responsabilidades:
- Registrar o **contexto da aplica√ß√£o** (fun√ß√£o, escopo)
- Logar **acessos √† mem√≥ria** (endere√ßos, tipos)
- Calcular **sequ√™ncias de stride** (diferen√ßas entre acessos)
- Fornecer feedback para ML_Model

#### M√©todos:
```python
tracer.set_context(function_name: str, scope_id: int)
tracer.log_access(address: int, access_type: str = "READ")
tracer.get_stride_pattern(context_key: str) -> List[int]
tracer.get_timestamp() -> float
tracer.get_tracer_stats() -> Dict
```

#### Exemplo de Uso:
```python
tracer.set_context("matrix_multiply", 5)
tracer.log_access(0x1000)  # L√™ endere√ßo
tracer.log_access(0x1008)  # Pr√≥ximo acesso
tracer.log_access(0x1010)  # Stride = 8 bytes

strides = tracer.get_stride_pattern()  # [8, 8] ‚Üí Padr√£o regular!
```

---

### 3. **ALPModel (M2)** - Modelo de ML

**Arquivo**: `alp_model.py`

Modelo de Previs√£o de Localidade Adaptativa baseado em LSTM conceitual.

#### Responsabilidades:
- **Preprocessar** sequ√™ncias de stride (normaliza√ß√£o, padroniza√ß√£o)
- **Executar infer√™ncia** para prever pr√≥ximos blocos
- **Calcular confian√ßa** da previs√£o (rigor >= 99.9%)
- **Manter hist√≥rico** de padr√µes por contexto

#### M√©todo Principal:
```python
prediction = model.predict(
    context: str,        # Ex: "matrix_multiply_5"
    accesses: List[int]  # Hist√≥rico de endere√ßos
) -> Dict

# Retorna:
{
    'blocks': [0x1008, 0x1010, 0x1018],  # Blocos a prefetch
    'confidence': 0.99999,                # 99.999% de confian√ßa
    'ttid_pim': 95,                       # Tempo estimado PIM (ms)
    'ttid_cpu': 160,                      # Tempo estimado CPU (ms)
    'stride_pattern': 'Regular (mean=8, std=0.5)'
}
```

#### L√≥gica de Rigor:

| Contexto | Padr√£o | Confian√ßa | Blocos | A√ß√£o |
|----------|--------|-----------|--------|------|
| `matrix_multiply` + stride regular | Linear | 99.999% | ‚úì Prever | PIM |
| Loop gen√©rico + padr√£o moderado | Moderado | 99.5% | ‚úì Prever | Decis√£o |
| Contexto novo / padr√£o ca√≥tico | Desconhecido | 75% | ‚úó Vazio | CPU |

---

### 4. **PredictionEngine (M2)** - Motor de Decis√£o

**Arquivo**: `prediction_engine.py`

Toma a decis√£o final: **PIM** ou **CPU**.

#### Algoritmo OLP-ALP:

```python
def decide(confidence, ttid_pim, ttid_cpu):
    ttid_gain = ttid_cpu - ttid_pim
    
    if confidence >= 0.999 and ttid_gain > 0:
        return "PIM"      # Confian√ßa alta + ganho positivo
    else:
        return "CPU"      # Fallback seguro
```

#### M√©todo:
```python
decision = engine.execute_task(
    task_function,
    task_data,
    tracer,
    ml_model,
    hal_driver
) -> Dict

# Retorna:
{
    'destination': 'PIM',           # PIM ou CPU
    'confidence': 0.99999,
    'ttid': 95.2,                   # Tempo real de execu√ß√£o (ms)
    'ttid_estimate': 95,            # Tempo estimado
    'result': <resultado da tarefa>,
    'gain': 65                       # ttid_cpu - ttid_pim
}
```

---

### 5. **OLP-HAL Driver** - Abstra√ß√£o de Hardware

**Arquivo**: `olp_hal_driver.py`

Comunica√ß√£o de baixa lat√™ncia com PIM/REM.

#### Interfaces Principais:

```python
# 1. Carregar Tarefa no PIM via DMA
hal_driver.load_task_pim(
    task_id: int,      # ID da tarefa
    data_ptr: int,     # Ponteiro para dados
    num_blocks: int    # N√∫mero de blocos
) -> bool

# 2. Enviar Sinal de Interrup√ß√£o Cr√≠tica via REM
hal_driver.send_rem_interrupt(
    error_code: int,
    context: str = ""
) -> bool

# 3. Monitorar TTID em Tempo Real
ttid_ms = hal_driver.get_current_ttid() -> float

# 4. Obter Relat√≥rio de Hardware
stats = hal_driver.get_hardware_stats() -> Dict
```

#### Registradores de Hardware (Simulados):

| Registrador | Endere√ßo | Fun√ß√£o |
|-------------|----------|--------|
| `PIM_TASK_REGISTER` | 0x80000000 | Controlar tarefa PIM |
| `PIM_DATA_PTR_REGISTER` | 0x80000004 | Dados a transferir |
| `PIM_PREFETCH_DMA_CONFIG` | 0x80000008 | Configurar DMA |
| `REM_INTERRUPT_REGISTER` | 0x90000000 | Pulso √≥ptico (REM) |
| `HW_TTID_COUNTER` | 0xA0000000 | Contador de lat√™ncia |
| `HW_ENERGY_MONITOR` | 0xA0000004 | Consumo de energia |

#### Caracter√≠sticas de Rigor:
- **Acesso Direto**: Bypasssa overhead do SO
- **DMA**: Transfer√™ncia direta de dados (ultra-r√°pido)
- **Ultra-Baixa Lat√™ncia**: ~8ns para REM
- **Auditoria Completa**: Log de todos os eventos

---

### 6. **PIMRecoveryModule (M3)** - Recupera√ß√£o de Falhas

**Arquivo**: `pim_recovery.py`

Detecta e recupera de falhas cr√≠ticas no PIM.

#### Responsabilidades:
- Manter **checkpoints** de estado v√°lido
- Monitorar **sinais de falha** (REM)
- Fazer **rollback** para checkpoint seguro
- Reexecutar na **CPU** como fallback

#### M√©todos:

```python
# 1. Registrar Checkpoint
recovery.register_checkpoint(
    address: int,              # Endere√ßo de estado v√°lido
    checkpoint_name: str = ""
) -> None

# 2. Tratar Falha Cr√≠tica
recovery.handle_critical_interrupt(
    error_code: int,
    context: str
) -> None

# 3. Obter Estat√≠sticas
stats = recovery.get_recovery_stats() -> Dict
```

#### Fases de Recupera√ß√£o:

```
1. DETEC√á√ÉO: Hardware PIM reporta erro via REM
   ‚Üì
2. LOG: Registrar erro e contexto
   ‚Üì
3. ROLLBACK: Retornar ao √∫ltimo checkpoint v√°lido
   ‚Üì
4. CPU_FALLBACK: Reexecutar a tarefa na CPU
   ‚Üì
5. VALIDA√á√ÉO: Garantir resultado correto ao usu√°rio
```

---

## Fluxo de Execu√ß√£o

### Passo a Passo Detalhado

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. DESENVOLVEDOR DEFINE CONTEXTO                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

olp_api.set_context("training_loop_forward_pass", iteration=5)

Resultado:
  - RuntimeTracer inicia rastreamento para este contexto
  - Pilha de contextos atualizada
  - ID √∫nico gerado: "training_loop_forward_pass_5"

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. DESENVOLVEDOR REGISTRA CHECKPOINT                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

olp_api.register_checkpoint(0x500 + 5*8, "batch_5_start")

Resultado:
  - PIMRecoveryModule armazena checkpoint
  - Endere√ßo marcado como "√∫ltimo bom estado"
  - ID √∫nico gerado: "batch_5_start"

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. DESENVOLVEDOR EXECUTA TAREFA OTIMIZADA                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

result = olp_api.execute_optimized(matrix_multiply, data_addresses)

Resultado interno (detalhado):

  [Fase 1: Coleta de Dados]
    RuntimeTracer.log_access(0x1000)  # Coleta todos os acessos
    RuntimeTracer.log_access(0x1008)  # durante a execu√ß√£o
    RuntimeTracer.log_access(0x1010)  # da tarefa
    
    Stride detectado: [8, 8] ‚Üí Padr√£o MUITO regular!
  
  [Fase 2: Previs√£o via ML]
    ALPModel.preprocess_input("training_loop_forward_pass_5", accesses)
    
    Input: [0x1000, 0x1008, 0x1010] (endere√ßos hist√≥ricos)
    Output: [0x1018, 0x1020, 0x1028] (pr√≥ximos blocos preditos)
    
    Predict():
      - Contexto: "training_loop_forward_pass"
      - Padr√£o: LSTM detecta "loop matrix_multiply"
      - Confian√ßa: 99.999% (stride muito regular)
      - TTID estimado PIM: 95 ms
      - TTID estimado CPU: 160 ms
  
  [Fase 3: Decis√£o OLP-ALP]
    PredictionEngine:
      - Confian√ßa 99.999% >= 99.9%? ‚úì SIM
      - Ganho = 160 - 95 = 65 ms > 0? ‚úì SIM
      - Decis√£o: DESVIA PARA PIM
  
  [Fase 4: Execu√ß√£o no PIM]
    OLPHALDriver.load_task_pim(
      task_id=12345,
      data_ptr=0x1000,
      num_blocks=3
    )
    
    Hardware:
      1. DMA transfere blocos [0x1018, 0x1020, 0x1028] para cache PIM
      2. PIM Unit executa matrix_multiply em paralelo
      3. Resultado pronto em ~95 ms (real TTID)
  
  [Fase 5: Retorno ao Aplicativo]
    OLP_API retorna resultado
    Log registrado: "Task #1 -> PIM (confian√ßa: 99.999%)"
```

---

## Decis√£o OLP-ALP

### L√≥gica de Rigor

```python
def olp_alp_decision(confidence, ttid_pim, ttid_cpu):
    """
    Algoritmo de decis√£o com dois crit√©rios de rigor:
    1. Confian√ßa >= 99.9% (C >= 0.999)
    2. Ganho positivo (TTID_gain > 0)
    """
    
    ttid_gain = ttid_cpu - ttid_pim
    
    # Crit√©rio 1: Confian√ßa Suficiente
    if confidence < 0.999:
        print("‚ùå Confian√ßa insuficiente: usar CPU")
        return "CPU"
    
    # Crit√©rio 2: Ganho Positivo
    if ttid_gain <= 0:
        print("‚ùå Sem ganho de lat√™ncia: usar CPU")
        return "CPU"
    
    # Ambos crit√©rios satisfeitos
    print(f"‚úì DESVIAR PARA PIM")
    print(f"  - Confian√ßa: {confidence*100:.3f}%")
    print(f"  - Ganho TTID: {ttid_gain} ms")
    return "PIM"
```

### Tabela de Decis√µes

| Confian√ßa | Ganho TTID | Decis√£o | Justificativa |
|-----------|-----------|---------|---------------|
| 99.999% | +65 ms | **PIM** | Ambos crit√©rios ok |
| 99.5% | +50 ms | **CPU** | Confian√ßa baixa demais |
| 99.999% | -10 ms | **CPU** | Sem ganho de lat√™ncia |
| 95% | +100 ms | **CPU** | Confian√ßa cr√≠tica |
| 99.9% | +1 ms | **PIM** | Marginal, mas ok |

---

## Integra√ß√£o e Uso

### Passo 1: Instalar Depend√™ncias

```bash
# Nenhuma depend√™ncia externa √© estritamente necess√°ria
# Usa apenas stdlib do Python
```

### Passo 2: Importar OLP

```python
from olp_core_api import OLP_API
```

### Passo 3: Usar a API (3 Opera√ß√µes)

```python
# 1. Definir contexto
OLP_API.set_context("training_loop", iteration=1)

# 2. Registrar checkpoint de seguran√ßa
OLP_API.register_checkpoint(0x500, "checkpoint_1")

# 3. Executar com otimiza√ß√£o
def minha_tarefa(dados):
    return sum(dados) * 2

dados_enderecos = [0x1000 + i*8 for i in range(10)]
resultado = OLP_API.execute_optimized(minha_tarefa, dados_enderecos)

# 4. Obter relat√≥rio
relatorio = OLP_API.get_full_system_report()
print(relatorio)
```

---

## Exemplos Pr√°ticos

### Exemplo 1: Loop de Treinamento ML

```python
from olp_core_api import OLP_API

def forward_pass(batch_data):
    """Passe forward de uma rede neural."""
    result = 0
    for x in batch_data:
        result += x ** 2
    return result

# Loop de treinamento com OLP
for epoch in range(1, 11):
    for batch in range(1, 51):
        # 1. Define contexto espec√≠fico
        OLP_API.set_context("training_forward_pass", epoch * 100 + batch)
        
        # 2. Checkpoint para seguran√ßa
        checkpoint_addr = 0x1000 + (epoch * 50 + batch) * 8
        OLP_API.register_checkpoint(checkpoint_addr, f"epoch_{epoch}_batch_{batch}")
        
        # 3. Simular dados de entrada (endere√ßos de mem√≥ria)
        batch_data = [0x2000 + i*8 for i in range(batch * 10)]
        
        # 4. Executar com OLP decidindo PIM vs CPU
        loss = OLP_API.execute_optimized(forward_pass, batch_data)
        
        if batch % 10 == 0:
            print(f"Epoch {epoch}, Batch {batch}: Loss = {loss}")
```

### Exemplo 2: Big Data Processing

```python
def aggregate_data(addresses):
    """Agregar dados com padr√£o de acesso previs√≠vel."""
    total = sum(addresses)
    return total // len(addresses)

# Processamento de dados com OLP
for chunk_id in range(1, 100):
    # Define contexto de processamento
    OLP_API.set_context("big_data_aggregation", chunk_id)
    OLP_API.register_checkpoint(0x5000 + chunk_id * 8, f"chunk_{chunk_id}")
    
    # Endere√ßos de dados (em padr√£o linear)
    chunk_addresses = [0x10000 + i*64 for i in range(1000)]
    
    # OLP decide automaticamente
    result = OLP_API.execute_optimized(aggregate_data, chunk_addresses)
```

---

## Pr√≥ximos Passos

### Curto Prazo (1-2 semanas)
1. ‚úÖ Implementar suite de testes (unit + integration)
2. ‚úÖ Otimizar lat√™ncia do OLP-HAL Driver
3. ‚úÖ Implementar cache de previs√µes para contextos repetidos
4. ‚úÖ Documenta√ß√£o de API (Sphinx)

### M√©dio Prazo (1-2 meses)
1. Integra√ß√£o com LSTM weights reais (treinar com datasets reais)
2. Dashboard de monitoring em tempo real
3. Perfil de performance (micro-benchmarks)
4. Suporte a m√∫ltiplas arquiteturas de PIM

### Longo Prazo (3-6 meses)
1. Hardware real: implementar driver para PIM f√≠sico
2. Otimiza√ß√µes adaptativas (ajustar threshold de confian√ßa)
3. Suporte a m√∫ltiplos contextos concorrentes
4. Publica√ß√£o de resultados (papers, conferences)

---

## Refer√™ncias T√©cnicas

### Documenta√ß√£o de Componentes
- `alp_model.py`: Modelo de ML com LSTM conceitual
- `olp_hal_driver.py`: Driver de comunica√ß√£o com hardware
- `olp_core_api.py`: Interface principal para desenvolvedores
- `runtime_tracer.py`: Coleta de padr√µes de acesso
- `prediction_engine.py`: Motor de decis√£o OLP-ALP
- `pim_recovery.py`: M√≥dulo de recupera√ß√£o de falhas

### Princ√≠pios de Design
- **Simplicidade**: 3 chamadas de API para o desenvolvedor
- **Rigor**: Confian√ßa >= 99.9% para decis√µes cr√≠ticas
- **Seguran√ßa**: Recovery autom√°tico em caso de falhas
- **Lat√™ncia**: Ultra-baixa (<1ms overhead)

---

**Fim do Guia T√©cnico**
